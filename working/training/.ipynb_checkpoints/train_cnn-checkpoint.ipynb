{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (3.1.0)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.62.1-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from librosa)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa)\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.0 (from librosa)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
      "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.45.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.2-cp312-cp312-win_amd64.whl (72 kB)\n",
      "Downloading numba-0.62.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.6/2.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 9.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  8.7/8.7 MB 44.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 30.1 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 13.6/38.6 MB 65.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.2/38.6 MB 61.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 64.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 49.0 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.45.1-cp312-cp312-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.7/38.1 MB 18.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.2/38.1 MB 63.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 69.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 60.6 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, msgpack, llvmlite, lazy_loader, joblib, scikit-learn, numba\n",
      "Successfully installed joblib-1.5.2 lazy_loader-0.4 llvmlite-0.45.1 msgpack-1.1.2 numba-0.62.1 scikit-learn-1.7.2 scipy-1.16.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 31.2 MB/s eta 0:00:00\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: audiomentations in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (0.43.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: numpy<3,>=1.22.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (2.0.2)\n",
      "Requirement already satisfied: numpy-minmax<1,>=0.3.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (0.5.0)\n",
      "Requirement already satisfied: numpy-rms<1,>=0.4.2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (0.6.0)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.12.0,>=0.8.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (0.11.0)\n",
      "Requirement already satisfied: python-stretch<1,>=0.3.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (0.3.1)\n",
      "Requirement already satisfied: scipy<2,>=1.4 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (1.16.3)\n",
      "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from audiomentations) (0.5.0.post1)\n",
      "Requirement already satisfied: torch==2.9.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torchaudio) (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from torch==2.9.1->torchaudio) (75.1.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.62.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.8.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.21)\n",
      "Requirement already satisfied: packaging in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch==2.9.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from jinja2->torch==2.9.1->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install audiomentations torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR : C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\n",
      "DATA_DIR : C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\n",
      "FEAT_DIR : C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\features\n"
     ]
    }
   ],
   "source": [
    "# ----------- 1. Config -----------\n",
    "SR = 16000             #16kHz\n",
    "N_FFT = 1024           # ~64 ms\n",
    "HOP = 256              # ~16 ms\n",
    "WIN = 1024\n",
    "N_MELS = 64\n",
    "N_MFCC = 13\n",
    "\n",
    "MAX_FRAMES = 500 \n",
    "\n",
    "USE_LOGMEL = True\n",
    "USE_MFCC39 = True\n",
    "USE_CHROMA = True\n",
    "#DATA_DIR = Path(\"/kaggle/working/processed\")\n",
    "CURRENT_DIR = Path().resolve()\n",
    "ROOT_DIR = CURRENT_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / \"processed\"\n",
    "FEAT_DIR = ROOT_DIR / \"features\"\n",
    "FEAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"ROOT_DIR :\", ROOT_DIR)\n",
    "print(\"DATA_DIR :\", DATA_DIR)\n",
    "print(\"FEAT_DIR :\", FEAT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=0.4 c√≥ nghƒ©a l√† m·ªói ph√©p bi·∫øn ƒë·ªïi c√≥ 40% c∆° h·ªôi ƒë∆∞·ª£c √°p d·ª•ng\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.010, p=0.2),\n",
    "    TimeStretch(min_rate=0.9, max_rate=1.1, p=0.2),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.2),\n",
    "    Shift(p=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 2. Utils -----------\n",
    "def load_wav(path, sr = SR):\n",
    "    # ƒë·ªçc wav, resample v·ªÅ SR,chu·∫©n h√≥a bi√™n ƒë·ªô [-1, 1]\n",
    "    y, _ = librosa.load(Path(path), sr=sr, mono=True)\n",
    "    if np.max(np.abs(y)) > 0:\n",
    "        y = y / np.max(np.abs(y))\n",
    "    return y\n",
    "#y:  m·∫£ng NumPy 1 chi·ªÅu ch·ª©a c√°c gi√° tr·ªã bi√™n ƒë·ªô c·ªßa s√≥ng √¢m theo th·ªùi gian\n",
    "def extract_logmel(y, sr = SR):\n",
    "    S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP, win_length=WIN))**2\n",
    "    M = librosa.feature.melspectrogram(S=S, sr=sr, n_mels=N_MELS)\n",
    "    logmel = librosa.power_to_db(M, ref=np.max)\n",
    "    return logmel\n",
    "#Ma tr·∫≠n 2D logmel c√≥ k√≠ch th∆∞·ªõc (N_MELS, T), \n",
    "#trong ƒë√≥ N_MELS l√† s·ªë l∆∞·ª£ng d·∫£i Mel, T l√† s·ªë khung th·ªùi gian. \n",
    "def extract_mfcc_block(y, sr = SR):\n",
    "    M = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT,\n",
    "                                       hop_length=HOP, win_length=WIN,\n",
    "                                       n_mels=N_MELS)\n",
    "    db = librosa.power_to_db(M, ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(S=db, n_mfcc=N_MFCC)\n",
    "    d1 = librosa.feature.delta(mfcc)\n",
    "    d2 = librosa.feature.delta(mfcc, order=2)\n",
    "    return np.concatenate([mfcc, d1, d2], axis=0)\n",
    "#Ma tr·∫≠n 2D c√≥ k√≠ch th∆∞·ªõc (3 * N_MFCC, T).\n",
    "def extract_chroma(y, sr=SR):\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP, win_length=WIN)\n",
    "    return chroma\n",
    "#Ma tr·∫≠n 2D c√≥ k√≠ch th∆∞·ªõc (12, T)\n",
    "def pad_or_trim_feat(X, T_target, pad_value=0.0):\n",
    "    # X: (C, T) -> (C, T_target) b·∫±ng c√°ch c·∫Øt ho·∫∑c ƒë·ªám 0 ·ªü cu·ªëi\n",
    "    C, T = X.shape\n",
    "    if T == T_target:\n",
    "        return X\n",
    "    if T > T_target:\n",
    "        return X[:, :T_target]\n",
    "    pad = np.full((C, T_target - T), pad_value, dtype=X.dtype)\n",
    "    return np.concatenate([X, pad], axis=1)\n",
    "\n",
    "def stack_features(y):\n",
    "    \"\"\"\n",
    "    Gh√©p c√°c kh·ªëi ƒë·∫∑c tr∆∞ng theo tr·ª•c k√™nh (C):\n",
    "      - log-Mel: (N_MELS, T)\n",
    "      - MFCC39: (39, T)\n",
    "      - Chroma: (12, T)\n",
    "    Tr·∫£ v·ªÅ: (C, T)\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    if USE_LOGMEL:\n",
    "        feats.append(extract_logmel(y))\n",
    "    if USE_MFCC39:\n",
    "        feats.append(extract_mfcc_block(y))\n",
    "    if USE_CHROMA:\n",
    "        feats.append(extract_chroma(y))\n",
    "    if len(feats) == 0:\n",
    "        raise ValueError(\"B·∫°n ph·∫£i b·∫≠t √≠t nh·∫•t m·ªôt ƒë·∫∑c tr∆∞ng (LOGMEL/MFCC/CHROMA).\")\n",
    "    # Kh·ªõp T (tr∆∞·ªùng h·ª£p sai l·ªách 1-2 frame do l√†m tr√≤n) b·∫±ng c√°ch c·∫Øt theo T nh·ªè nh·∫•t\n",
    "    T_min = min(f.shape[1] for f in feats)\n",
    "    feats = [f[:, :T_min] for f in feats]\n",
    "    return np.concatenate(feats, axis=0)\n",
    "\n",
    "def compute_norm_stats(X):\n",
    "    \"\"\"X: (N, C, T) -> t√≠nh mean/std theo t·ª´ng k√™nh C tr√™n to√†n b·ªô frames.\"\"\"\n",
    "    N, C, T = X.shape\n",
    "    flat = X.transpose(1, 0, 2).reshape(C, N*T)\n",
    "    mean = flat.mean(axis=1)\n",
    "    std = flat.std(axis=1) + 1e-8\n",
    "    return mean, std\n",
    "\n",
    "def apply_norm(X, mean, std):\n",
    "    \"\"\"Pre-emphasis theo k√™nh: (N, C, T) -> normalized.\"\"\"\n",
    "    return (X - mean[None, :, None]) / std[None, :, None]\n",
    "\n",
    "def read_split(split_name):\n",
    "    df = pd.read_csv(DATA_DIR / f\"{split_name}_final.csv\")\n",
    "    # ƒê·∫£m b·∫£o ƒë√∫ng ki·ªÉu\n",
    "    df[\"file_path\"] = df[\"file_path\"].astype(str)\n",
    "    df[\"label_id\"] = df[\"label_id\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Tr√≠ch xu·∫•t cho 1 split\n",
    "# =========================\n",
    "def extract_split(split_name, T_target=None):\n",
    "    \"\"\"\n",
    "    split_name: 'train' | 'val' | 'test'\n",
    "    T_target: n·∫øu None (th∆∞·ªùng cho train), s·∫Ω ch·ªçn = min(T_max, MAX_FRAMES)\n",
    "    Tr·∫£ v·ªÅ: X_pad (N,C,T), y (N,), paths (list), T_target (int)\n",
    "    \"\"\"\n",
    "    df = read_split(split_name)\n",
    "    X_list, y_list, paths = [], [], []\n",
    "    print(f\"Extracting features for '{split_name}' split...\")\n",
    "    for path, label_id in tqdm(zip(df[\"file_path\"].tolist(), df[\"label_id\"].tolist()),total = len(df)):\n",
    "        path = ROOT_DIR/path;\n",
    "        y = load_wav(path)\n",
    "        if split_name == \"train\":\n",
    "            y = augment(samples=y, sample_rate=SR)\n",
    "            \n",
    "        F = stack_features(y)           # (C, T)\n",
    "        X_list.append(F)\n",
    "        y_list.append(int(label_id))\n",
    "        paths.append(str(path))\n",
    "\n",
    "    # Ch·ªçn s·ªë frame m·ª•c ti√™u\n",
    "    if T_target is None:\n",
    "        T_max = max(x.shape[1] for x in X_list)\n",
    "        T_target = min(T_max, MAX_FRAMES)\n",
    "\n",
    "    # Pad/trim v√† x·∫øp stack\n",
    "    X_pad = np.stack([pad_or_trim_feat(x, T_target) for x in X_list], axis=0)  # (N, C, T_target)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "\n",
    "    return X_pad, y, paths, T_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for 'train' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 921/921 [00:40<00:00, 22.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for 'val' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 231/231 [00:06<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for 'test' split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 288/288 [00:08<00:00, 33.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done feature extraction.\n",
      "Shapes -> X_train (921, 115, 330), X_val (231, 115, 330), X_test (288, 115, 330)\n",
      "Channels: 115 (LOGMEL=True, MFCC39=True, CHROMA=True)\n",
      "Norm stats saved at: C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\features\\meta.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # ---- Train ----\n",
    "    X_train, y_train, train_paths, T_target = extract_split(\"train\", T_target=None)\n",
    "    mean, std = compute_norm_stats(X_train)\n",
    "    X_train = apply_norm(X_train, mean, std)\n",
    "\n",
    "    # ---- Val/Test: d√πng c√πng T_target & c√πng mean/std c·ªßa train ----\n",
    "    X_val, y_val, val_paths, _ = extract_split(\"val\", T_target=T_target)\n",
    "    X_test, y_test, test_paths, _ = extract_split(\"test\", T_target=T_target)\n",
    "\n",
    "    X_val  = apply_norm(X_val,  mean, std)\n",
    "    X_test = apply_norm(X_test, mean, std)\n",
    "\n",
    "    # ---- L∆∞u npy ----\n",
    "    np.save(FEAT_DIR / \"X_train.npy\", X_train)\n",
    "    np.save(FEAT_DIR / \"y_train.npy\", y_train)\n",
    "    np.save(FEAT_DIR / \"X_val.npy\",   X_val)\n",
    "    np.save(FEAT_DIR / \"y_val.npy\",   y_val)\n",
    "    np.save(FEAT_DIR / \"X_test.npy\",  X_test)\n",
    "    np.save(FEAT_DIR / \"y_test.npy\",  y_test)\n",
    "\n",
    "    # ---- L∆∞u meta ----\n",
    "    channels = X_train.shape[1]\n",
    "    meta = {\n",
    "        \"sr\": SR,\n",
    "        \"n_fft\": N_FFT,\n",
    "        \"hop\": HOP,\n",
    "        \"win\": WIN,\n",
    "        \"n_mels\": N_MELS,\n",
    "        \"n_mfcc\": N_MFCC,\n",
    "        \"use_logmel\": USE_LOGMEL,\n",
    "        \"use_mfcc39\": USE_MFCC39,\n",
    "        \"use_chroma\": USE_CHROMA,\n",
    "        \"channels\": int(channels),\n",
    "        \"frames_target\": int(X_train.shape[2]),\n",
    "        \"max_frames_cap\": MAX_FRAMES,\n",
    "        \"mean\": [float(m) for m in mean],\n",
    "        \"std\":  [float(s) for s in std],\n",
    "        \"train_size\": int(X_train.shape[0]),\n",
    "        \"val_size\": int(X_val.shape[0]),\n",
    "        \"test_size\": int(X_test.shape[0]),\n",
    "        \"train_paths_head\": train_paths[:3],  # ƒë·ªÉ debug nhanh\n",
    "        \"val_paths_head\":   val_paths[:3],\n",
    "        \"test_paths_head\":  test_paths[:3],\n",
    "    }\n",
    "    with open(FEAT_DIR / \"meta.json\", \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    print(\"Done feature extraction.\")\n",
    "    print(f\"Shapes -> X_train {X_train.shape}, X_val {X_val.shape}, X_test {X_test.shape}\")\n",
    "    print(f\"Channels: {channels} (LOGMEL={USE_LOGMEL}, MFCC39={USE_MFCC39}, CHROMA={USE_CHROMA})\")\n",
    "    print(f\"Norm stats saved at: {FEAT_DIR/'meta.json'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (921, 115, 330) (231, 115, 330) (288, 115, 330)\n",
      "Classes: 8\n"
     ]
    }
   ],
   "source": [
    "# === 4. LOAD DATA ===\n",
    "import numpy as np, os, json, torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#FEATURES_DIR = \"/kaggle/working/processed/features\"  # ho·∫∑c ƒë∆∞·ªùng d·∫´n b·∫°n l∆∞u\n",
    "FEATURES_DIR = FEAT_DIR\n",
    "#OUT_DIR = \"/kaggle/working\"\n",
    "OUT_DIR = ROOT_DIR\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "X_train = np.load(os.path.join(FEATURES_DIR, \"X_train.npy\"))\n",
    "y_train = np.load(os.path.join(FEATURES_DIR, \"y_train.npy\"))\n",
    "X_val   = np.load(os.path.join(FEATURES_DIR, \"X_val.npy\"))\n",
    "y_val   = np.load(os.path.join(FEATURES_DIR, \"y_val.npy\"))\n",
    "X_test  = np.load(os.path.join(FEATURES_DIR, \"X_test.npy\"))\n",
    "y_test  = np.load(os.path.join(FEATURES_DIR, \"y_test.npy\"))\n",
    "\n",
    "with open(os.path.join(FEATURES_DIR, \"meta.json\")) as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Classes:\", len(set(y_train)))\n",
    "\n",
    "# Reshape cho CNN2D: (N, 1, C, T)\n",
    "X_train = X_train[:, None, :, :].astype(\"float32\")\n",
    "X_val   = X_val[:, None, :, :].astype(\"float32\")\n",
    "X_test  = X_test[:, None, :, :].astype(\"float32\")\n",
    "\n",
    "# Dataloader\n",
    "BATCH_SIZE = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dl = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n",
    "                      batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)),\n",
    "                    batch_size=BATCH_SIZE)\n",
    "test_dl = DataLoader(TensorDataset(torch.tensor(X_test), torch.tensor(y_test)),\n",
    "                     batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SER_CNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 7), stride=(1, 1), padding=(2, 3))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# === 5. MODEL DEFINITION ===\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SER_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (5,7), padding=(2,3)), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(32, 64, (3,5), padding=(1,2)), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(64, 128, (3,5), padding=(1,2)), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Dropout(0.4), #0.25 -> 0.3 ->0.4\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 128), nn.ReLU(), nn.Dropout(0.5), #0.3->0.4 -> 0.5\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Kh·ªüi t·∫°o\n",
    "num_classes = len(set(y_train))\n",
    "model = SER_CNN(num_classes).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ª≠ d·ª•ng Class Weights: [1.8568548  0.9359756  0.9359756  0.9359756  0.9359756  0.94364756\n",
      " 0.9359756  0.94364756]\n"
     ]
    }
   ],
   "source": [
    "# === 6. TRAINING SETUP ===\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "class_labels = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight = 'balanced',\n",
    "    classes = class_labels,\n",
    "    y = y_train\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype = torch.float).to(device)\n",
    "# In ra c√°c tr·ªçng s·ªë ƒë√£ t√≠nh ƒë·ªÉ ki·ªÉm tra, th·∫•y c√°c l·ªõp hi·∫øm c√≥ s·ªë l·ªõn h∆°n\n",
    "print(f\"S·ª≠ d·ª•ng Class Weights: {class_weights_tensor.cpu().numpy()}\")\n",
    "#Phat nang hon neu mo hinh du doan sai mot lop co trong so cao\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights_tensor)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
    "# Kh·ªüi t·∫°o scheduler ƒë·ªÉ t·ª± ƒë·ªông gi·∫£m learning rate\n",
    "# mode='max': Theo d√µi m·ªôt ch·ªâ s·ªë c·∫ßn ƒë∆∞·ª£c t·ªëi ƒëa h√≥a (F1-score)\n",
    "# factor=0.5: Khi gi·∫£m, learning rate s·∫Ω ƒë∆∞·ª£c nh√¢n v·ªõi 0.5 \n",
    "# patience=5: N·∫øu F1-score kh√¥ng c·∫£i thi·ªán trong 5 epoch li√™n ti·∫øp, learning rate s·∫Ω gi·∫£m\n",
    "# verbose=True: In ra th√¥ng b√°o m·ªói khi learning rate ƒë∆∞·ª£c gi·∫£m\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=5)\n",
    "\n",
    "#Pipeline SpecAugment\n",
    "# shape[2] l√† s·ªë k√™nh ƒë·∫∑c tr∆∞ng (115).\n",
    "N_MELS_IN_FEATURES = X_train.shape[2] \n",
    "#shape[3] l√† s·ªë khung th·ªùi gian (330).\n",
    "FRAMES_IN_FEATURES = X_train.shape[3] \n",
    "\n",
    "# T√≠nh to√°n tham s·ªë che Che t·ªëi ƒëa 1/5 t·ªïng s·ªë d·∫£i t·∫ßn.\n",
    "freq_mask_param = N_MELS_IN_FEATURES // 5\n",
    "# Che t·ªëi ƒëa 1/7 t·ªïng s·ªë khung th·ªùi gian.\n",
    "time_mask_param = FRAMES_IN_FEATURES // 7\n",
    "\n",
    "# T·∫°o m·ªôt pipeline tu·∫ßn t·ª± (Sequential) ƒë·ªÉ √°p d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi SpecAugment.\n",
    "# N√≥ s·∫Ω th·ª±c hi·ªán che t·∫ßn s·ªë tr∆∞·ªõc, r·ªìi ƒë·∫øn che th·ªùi gian.\n",
    "spec_augment = torch.nn.Sequential(\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask_param),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=time_mask_param),\n",
    ").to(device)\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb).argmax(1)\n",
    "            all_true.append(yb.cpu().numpy())\n",
    "            all_pred.append(pred.cpu().numpy())\n",
    "    y_true = np.concatenate(all_true); y_pred = np.concatenate(all_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: loss=2.0761  val_acc=0.203  val_f1=0.119 lr=3.0e-04\n",
      " New best F1: 0.1192 (previously -1.0000). Saving model...\n",
      "Epoch 02: loss=2.0540  val_acc=0.225  val_f1=0.126 lr=3.0e-04\n",
      " New best F1: 0.1263 (previously 0.1192). Saving model...\n",
      "Epoch 03: loss=2.0183  val_acc=0.229  val_f1=0.133 lr=3.0e-04\n",
      " New best F1: 0.1335 (previously 0.1263). Saving model...\n",
      "Epoch 04: loss=1.9791  val_acc=0.255  val_f1=0.146 lr=3.0e-04\n",
      " New best F1: 0.1456 (previously 0.1335). Saving model...\n",
      "Epoch 05: loss=1.9314  val_acc=0.342  val_f1=0.216 lr=3.0e-04\n",
      " New best F1: 0.2164 (previously 0.1456). Saving model...\n",
      "Epoch 06: loss=1.8890  val_acc=0.299  val_f1=0.203 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 9/10\n",
      "Epoch 07: loss=1.8414  val_acc=0.359  val_f1=0.269 lr=3.0e-04\n",
      " New best F1: 0.2693 (previously 0.2164). Saving model...\n",
      "Epoch 08: loss=1.8036  val_acc=0.325  val_f1=0.246 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 9/10\n",
      "Epoch 09: loss=1.7575  val_acc=0.338  val_f1=0.252 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 8/10\n",
      "Epoch 10: loss=1.7128  val_acc=0.182  val_f1=0.111 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 7/10\n",
      "Epoch 11: loss=1.7035  val_acc=0.190  val_f1=0.110 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 6/10\n",
      "Epoch 12: loss=1.6496  val_acc=0.294  val_f1=0.249 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 5/10\n",
      "Epoch 13: loss=1.6431  val_acc=0.251  val_f1=0.196 lr=3.0e-04\n",
      "F1 did not improve. Patience left: 4/10\n",
      "Epoch 14: loss=1.6116  val_acc=0.268  val_f1=0.202 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 3/10\n",
      "Epoch 15: loss=1.5874  val_acc=0.420  val_f1=0.369 lr=1.5e-04\n",
      " New best F1: 0.3691 (previously 0.2693). Saving model...\n",
      "Epoch 16: loss=1.5837  val_acc=0.433  val_f1=0.374 lr=1.5e-04\n",
      " New best F1: 0.3744 (previously 0.3691). Saving model...\n",
      "Epoch 17: loss=1.5632  val_acc=0.429  val_f1=0.379 lr=1.5e-04\n",
      " New best F1: 0.3785 (previously 0.3744). Saving model...\n",
      "Epoch 18: loss=1.5399  val_acc=0.333  val_f1=0.273 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 9/10\n",
      "Epoch 19: loss=1.5277  val_acc=0.286  val_f1=0.227 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 8/10\n",
      "Epoch 20: loss=1.5153  val_acc=0.368  val_f1=0.342 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 7/10\n",
      "Epoch 21: loss=1.5148  val_acc=0.455  val_f1=0.421 lr=1.5e-04\n",
      " New best F1: 0.4212 (previously 0.3785). Saving model...\n",
      "Epoch 22: loss=1.4971  val_acc=0.277  val_f1=0.207 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 9/10\n",
      "Epoch 23: loss=1.4928  val_acc=0.385  val_f1=0.307 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 8/10\n",
      "Epoch 24: loss=1.4594  val_acc=0.208  val_f1=0.150 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 7/10\n",
      "Epoch 25: loss=1.4453  val_acc=0.152  val_f1=0.062 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 6/10\n",
      "Epoch 26: loss=1.4674  val_acc=0.242  val_f1=0.169 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 5/10\n",
      "Epoch 27: loss=1.4224  val_acc=0.147  val_f1=0.057 lr=1.5e-04\n",
      "F1 did not improve. Patience left: 4/10\n",
      "Epoch 28: loss=1.4050  val_acc=0.385  val_f1=0.299 lr=7.5e-05\n",
      "F1 did not improve. Patience left: 3/10\n",
      "Epoch 29: loss=1.4001  val_acc=0.411  val_f1=0.388 lr=7.5e-05\n",
      "F1 did not improve. Patience left: 2/10\n",
      "Epoch 30: loss=1.3815  val_acc=0.320  val_f1=0.252 lr=7.5e-05\n",
      "F1 did not improve. Patience left: 1/10\n",
      "Epoch 31: loss=1.3843  val_acc=0.368  val_f1=0.328 lr=7.5e-05\n",
      "F1 did not improve. Patience left: 0/10\n",
      "‚èπ Early stopping.\n",
      "Best val F1: 0.42124925544650255\n"
     ]
    }
   ],
   "source": [
    "# === 7. TRAIN LOOP ===\n",
    "EPOCHS = 60\n",
    "best_f1, patience = -1, 10\n",
    "left = patience\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        #xb = spec_augment(xb)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    train_loss = total_loss / len(train_dl.dataset)\n",
    "    \n",
    "    val_acc, val_f1 = evaluate(model, val_dl)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_f1)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}: loss={train_loss:.4f}  val_acc={val_acc:.3f}  val_f1={val_f1:.3f} lr={current_lr:.1e}\")\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        print(f\" New best F1: {val_f1:.4f} (previously {best_f1:.4f}). Saving model...\")\n",
    "        best_f1, left = val_f1, patience\n",
    "        torch.save(model.state_dict(), os.path.join(OUT_DIR,\"models\", \"ser_best.pt\"))\n",
    "    else:\n",
    "        left -= 1\n",
    "        print(f\"F1 did not improve. Patience left: {left}/{patience}\")\n",
    "        if left == 0:\n",
    "            print(\"‚èπ Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"Best val F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.4271 | Macro-F1: 0.3714\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        19\n",
      "           1     0.3895    0.9737    0.5564        38\n",
      "           2     0.3529    0.1579    0.2182        38\n",
      "           3     0.1613    0.1316    0.1449        38\n",
      "           4     0.6667    0.5128    0.5797        39\n",
      "           5     0.3953    0.4359    0.4146        39\n",
      "           6     0.4783    0.5789    0.5238        38\n",
      "           7     0.7619    0.4103    0.5333        39\n",
      "\n",
      "    accuracy                         0.4271       288\n",
      "   macro avg     0.4007    0.4001    0.3714       288\n",
      "weighted avg     0.4293    0.4271    0.3973       288\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0 13  0  6  0  0  0  0]\n",
      " [ 1 37  0  0  0  0  0  0]\n",
      " [ 0  5  6  8  5 10  3  1]\n",
      " [ 0 24  1  5  0  5  3  0]\n",
      " [ 1  1  5  0 20  2  8  2]\n",
      " [ 2  7  2  3  1 17  5  2]\n",
      " [ 0  7  1  7  1  0 22  0]\n",
      " [ 1  1  2  2  3  9  5 16]]\n"
     ]
    }
   ],
   "source": [
    "# === 8. TEST EVALUATION ===\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(OUT_DIR,\"models\", \"ser_best.pt\"), map_location=device))\n",
    "acc, f1 = evaluate(model, test_dl)\n",
    "print(f\"\\n Test Accuracy: {acc:.4f} | Macro-F1: {f1:.4f}\")\n",
    "\n",
    "# In b√°o c√°o chi ti·∫øt\n",
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb).argmax(1).cpu().numpy()\n",
    "        y_true.append(yb.numpy()); y_pred.append(preds)\n",
    "y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (6.33.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fpt shop\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 3.9/8.1 MB 18.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.1 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.1/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_MAP = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "CURRENT_DIR = Path().resolve()\n",
    "ROOT_DIR = CURRENT_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / \"processed\"\n",
    "FEAT_DIR = ROOT_DIR / \"features\"\n",
    "FEAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FEATURES_DIR = FEAT_DIR\n",
    "#OUT_DIR = \"/kaggle/working\"\n",
    "OUTPUT_DIR = DATA_DIR\n",
    "OUTPUT_DIR_STR = str(OUTPUT_DIR) \n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Tr·ªçng s·ªë l·ªõp ƒë∆∞·ª£c t√≠nh to√°n ƒë·ªÉ x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng:\n",
      "  - L·ªõp 0 (neutral): 1.8569\n",
      "  - L·ªõp 1 (calm): 0.9360\n",
      "  - L·ªõp 2 (happy): 0.9360\n",
      "  - L·ªõp 3 (sad): 0.9360\n",
      "  - L·ªõp 4 (angry): 0.9360\n",
      "  - L·ªõp 5 (fearful): 0.9436\n",
      "  - L·ªõp 6 (disgust): 0.9360\n",
      "  - L·ªõp 7 (surprised): 0.9436\n",
      "============================================================\n",
      "============================================================\n",
      "üìä Dataset:\n",
      "   Train: 921 | Val: 231 | Test: 288\n",
      "üìê Config:\n",
      "   Input: (128, 200, 1)\n",
      "   Batch: 32\n",
      "============================================================\n",
      "\n",
      "  Building model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_21          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_22          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_23          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_24          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_25          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_26          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_average_pooling2d_3      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_27          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m320\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_21          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_18 (\u001b[38;5;33mActivation\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ         \u001b[38;5;34m9,248\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_22          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ           \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_19 (\u001b[38;5;33mActivation\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ        \u001b[38;5;34m18,496\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_23          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ           \u001b[38;5;34m256\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_20 (\u001b[38;5;33mActivation\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ        \u001b[38;5;34m36,928\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_24          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ           \u001b[38;5;34m256\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_21 (\u001b[38;5;33mActivation\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ        \u001b[38;5;34m73,856\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_25          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ           \u001b[38;5;34m512\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_22 (\u001b[38;5;33mActivation\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ       \u001b[38;5;34m147,584\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_26          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ           \u001b[38;5;34m512\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ activation_23 (\u001b[38;5;33mActivation\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_average_pooling2d_3      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            ‚îÇ        \u001b[38;5;34m66,048\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ batch_normalization_27          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            ‚îÇ         \u001b[38;5;34m2,048\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              ‚îÇ         \u001b[38;5;34m4,104\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">360,424</span> (1.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m360,424\u001b[0m (1.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">358,504</span> (1.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m358,504\u001b[0m (1.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training...\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 1e-07.\n",
      "Epoch 1/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1188 - loss: 2.8442 - macro_f1_score: 0.1122\n",
      "Epoch 1: val_macro_f1_score improved from -inf to 0.02866, saving model to C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\\ravdess_ser_cnn_simple.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 4s/step - accuracy: 0.1192 - loss: 2.8453 - macro_f1_score: 0.1127 - val_accuracy: 0.1295 - val_loss: 2.1487 - val_macro_f1_score: 0.0287 - learning_rate: 1.0000e-07\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 3.177299268245342e-06.\n",
      "Epoch 2/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1625 - loss: 2.7033 - macro_f1_score: 0.1523\n",
      "Epoch 2: val_macro_f1_score did not improve from 0.02866\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 4s/step - accuracy: 0.1617 - loss: 2.7047 - macro_f1_score: 0.1516 - val_accuracy: 0.1295 - val_loss: 2.1773 - val_macro_f1_score: 0.0287 - learning_rate: 3.1773e-06\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 1.2333423752026406e-05.\n",
      "Epoch 3/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.1551 - loss: 2.6432 - macro_f1_score: 0.1533\n",
      "Epoch 3: val_macro_f1_score did not improve from 0.02866\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 4s/step - accuracy: 0.1553 - loss: 2.6398 - macro_f1_score: 0.1535 - val_accuracy: 0.1295 - val_loss: 2.2139 - val_macro_f1_score: 0.0287 - learning_rate: 1.2333e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 2.7342919279117418e-05.\n",
      "Epoch 4/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1749 - loss: 2.4972 - macro_f1_score: 0.1655\n",
      "Epoch 4: val_macro_f1_score did not improve from 0.02866\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 4s/step - accuracy: 0.1751 - loss: 2.4956 - macro_f1_score: 0.1659 - val_accuracy: 0.1295 - val_loss: 2.2507 - val_macro_f1_score: 0.0287 - learning_rate: 2.7343e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 4.783620225598192e-05.\n",
      "Epoch 5/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1376 - loss: 2.5266 - macro_f1_score: 0.1342\n",
      "Epoch 5: val_macro_f1_score improved from 0.02866 to 0.02953, saving model to C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\\ravdess_ser_cnn_simple.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 4s/step - accuracy: 0.1383 - loss: 2.5247 - macro_f1_score: 0.1349 - val_accuracy: 0.1339 - val_loss: 2.2901 - val_macro_f1_score: 0.0295 - learning_rate: 4.7836e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 7.330866004242248e-05.\n",
      "Epoch 6/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.1960 - loss: 2.3381 - macro_f1_score: 0.1862\n",
      "Epoch 6: val_macro_f1_score did not improve from 0.02953\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 7s/step - accuracy: 0.1955 - loss: 2.3406 - macro_f1_score: 0.1859 - val_accuracy: 0.1339 - val_loss: 2.3461 - val_macro_f1_score: 0.0295 - learning_rate: 7.3309e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.00010313307618949638.\n",
      "Epoch 7/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.2394 - loss: 2.3645 - macro_f1_score: 0.2343\n",
      "Epoch 7: val_macro_f1_score did not improve from 0.02953\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 7s/step - accuracy: 0.2393 - loss: 2.3625 - macro_f1_score: 0.2342 - val_accuracy: 0.0670 - val_loss: 2.4541 - val_macro_f1_score: 0.0157 - learning_rate: 1.0313e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.00013657507459010043.\n",
      "Epoch 8/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.2383 - loss: 2.3483 - macro_f1_score: 0.2319\n",
      "Epoch 8: val_macro_f1_score did not improve from 0.02953\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 7s/step - accuracy: 0.2377 - loss: 2.3469 - macro_f1_score: 0.2313 - val_accuracy: 0.0670 - val_loss: 2.5970 - val_macro_f1_score: 0.0157 - learning_rate: 1.3658e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00017281120225598188.\n",
      "Epoch 9/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.2275 - loss: 2.3326 - macro_f1_score: 0.2189\n",
      "Epoch 9: val_macro_f1_score did not improve from 0.02953\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 7s/step - accuracy: 0.2275 - loss: 2.3326 - macro_f1_score: 0.2189 - val_accuracy: 0.0670 - val_loss: 2.7989 - val_macro_f1_score: 0.0157 - learning_rate: 1.7281e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00021094920546319427.\n",
      "Epoch 10/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2787 - loss: 2.2412 - macro_f1_score: 0.2704\n",
      "Epoch 10: val_macro_f1_score did not improve from 0.02953\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 7s/step - accuracy: 0.2785 - loss: 2.2397 - macro_f1_score: 0.2702 - val_accuracy: 0.0670 - val_loss: 2.8538 - val_macro_f1_score: 0.0158 - learning_rate: 2.1095e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00025005000000000003.\n",
      "Epoch 11/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2647 - loss: 2.1095 - macro_f1_score: 0.2522\n",
      "Epoch 11: val_macro_f1_score did not improve from 0.02953\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 7s/step - accuracy: 0.2649 - loss: 2.1093 - macro_f1_score: 0.2525 - val_accuracy: 0.0670 - val_loss: 2.9876 - val_macro_f1_score: 0.0157 - learning_rate: 2.5005e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0002891507945368058.\n",
      "Epoch 12/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.2799 - loss: 2.0383 - macro_f1_score: 0.2625\n",
      "Epoch 12: val_macro_f1_score improved from 0.02953 to 0.04334, saving model to C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\\ravdess_ser_cnn_simple.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 6s/step - accuracy: 0.2801 - loss: 2.0387 - macro_f1_score: 0.2628 - val_accuracy: 0.0982 - val_loss: 2.9095 - val_macro_f1_score: 0.0433 - learning_rate: 2.8915e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0003272887977440182.\n",
      "Epoch 13/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3351 - loss: 1.9402 - macro_f1_score: 0.3151\n",
      "Epoch 13: val_macro_f1_score did not improve from 0.04334\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 6s/step - accuracy: 0.3341 - loss: 1.9425 - macro_f1_score: 0.3142 - val_accuracy: 0.0670 - val_loss: 2.8714 - val_macro_f1_score: 0.0157 - learning_rate: 3.2729e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.00036352492540989975.\n",
      "Epoch 14/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3313 - loss: 1.9605 - macro_f1_score: 0.3057\n",
      "Epoch 14: val_macro_f1_score improved from 0.04334 to 0.14731, saving model to C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\\ravdess_ser_cnn_simple.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 6s/step - accuracy: 0.3311 - loss: 1.9604 - macro_f1_score: 0.3059 - val_accuracy: 0.2009 - val_loss: 2.5356 - val_macro_f1_score: 0.1473 - learning_rate: 3.6352e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00039696692381050363.\n",
      "Epoch 15/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3490 - loss: 1.8503 - macro_f1_score: 0.3135\n",
      "Epoch 15: val_macro_f1_score did not improve from 0.14731\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 7s/step - accuracy: 0.3488 - loss: 1.8511 - macro_f1_score: 0.3140 - val_accuracy: 0.2277 - val_loss: 2.9132 - val_macro_f1_score: 0.1181 - learning_rate: 3.9697e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0004267913399575776.\n",
      "Epoch 16/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3127 - loss: 1.8591 - macro_f1_score: 0.2943\n",
      "Epoch 16: val_macro_f1_score did not improve from 0.14731\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 7s/step - accuracy: 0.3138 - loss: 1.8574 - macro_f1_score: 0.2953 - val_accuracy: 0.1116 - val_loss: 2.8632 - val_macro_f1_score: 0.0574 - learning_rate: 4.2679e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0004522637977440182.\n",
      "Epoch 17/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.3600 - loss: 1.7879 - macro_f1_score: 0.3242\n",
      "Epoch 17: val_macro_f1_score did not improve from 0.14731\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 7s/step - accuracy: 0.3605 - loss: 1.7872 - macro_f1_score: 0.3252 - val_accuracy: 0.0670 - val_loss: 3.4206 - val_macro_f1_score: 0.0157 - learning_rate: 4.5226e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00047275708072088264.\n",
      "Epoch 18/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3363 - loss: 1.7872 - macro_f1_score: 0.3224\n",
      "Epoch 18: val_macro_f1_score improved from 0.14731 to 0.15581, saving model to C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\\ravdess_ser_cnn_simple.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 6s/step - accuracy: 0.3372 - loss: 1.7858 - macro_f1_score: 0.3234 - val_accuracy: 0.2188 - val_loss: 3.3742 - val_macro_f1_score: 0.1558 - learning_rate: 4.7276e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0004877665762479737.\n",
      "Epoch 19/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3606 - loss: 1.7617 - macro_f1_score: 0.3496\n",
      "Epoch 19: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 6s/step - accuracy: 0.3610 - loss: 1.7616 - macro_f1_score: 0.3500 - val_accuracy: 0.0670 - val_loss: 4.3035 - val_macro_f1_score: 0.0157 - learning_rate: 4.8777e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0004969227007317547.\n",
      "Epoch 20/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3960 - loss: 1.7535 - macro_f1_score: 0.3765\n",
      "Epoch 20: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 6s/step - accuracy: 0.3956 - loss: 1.7527 - macro_f1_score: 0.3764 - val_accuracy: 0.0714 - val_loss: 3.6055 - val_macro_f1_score: 0.0222 - learning_rate: 4.9692e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 21/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3739 - loss: 1.7435 - macro_f1_score: 0.3405\n",
      "Epoch 21: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 6s/step - accuracy: 0.3747 - loss: 1.7422 - macro_f1_score: 0.3418 - val_accuracy: 0.1830 - val_loss: 3.1959 - val_macro_f1_score: 0.0894 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0004969227007317547.\n",
      "Epoch 22/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3939 - loss: 1.6822 - macro_f1_score: 0.3685\n",
      "Epoch 22: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 6s/step - accuracy: 0.3943 - loss: 1.6818 - macro_f1_score: 0.3691 - val_accuracy: 0.1429 - val_loss: 5.3441 - val_macro_f1_score: 0.0456 - learning_rate: 4.9692e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0004877665762479737.\n",
      "Epoch 23/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4146 - loss: 1.6076 - macro_f1_score: 0.4025\n",
      "Epoch 23: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 6s/step - accuracy: 0.4149 - loss: 1.6076 - macro_f1_score: 0.4028 - val_accuracy: 0.1473 - val_loss: 5.3492 - val_macro_f1_score: 0.0584 - learning_rate: 4.8777e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.00047275708072088264.\n",
      "Epoch 24/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4594 - loss: 1.5273 - macro_f1_score: 0.4202\n",
      "Epoch 24: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 6s/step - accuracy: 0.4591 - loss: 1.5293 - macro_f1_score: 0.4204 - val_accuracy: 0.1786 - val_loss: 3.8388 - val_macro_f1_score: 0.0884 - learning_rate: 4.7276e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0004522637977440182.\n",
      "Epoch 25/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4312 - loss: 1.5982 - macro_f1_score: 0.4151\n",
      "Epoch 25: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 6s/step - accuracy: 0.4314 - loss: 1.5973 - macro_f1_score: 0.4155 - val_accuracy: 0.1741 - val_loss: 4.2423 - val_macro_f1_score: 0.0909 - learning_rate: 4.5226e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0004267913399575776.\n",
      "Epoch 26/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4207 - loss: 1.5742 - macro_f1_score: 0.4018\n",
      "Epoch 26: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 6s/step - accuracy: 0.4215 - loss: 1.5730 - macro_f1_score: 0.4026 - val_accuracy: 0.1339 - val_loss: 6.2001 - val_macro_f1_score: 0.0298 - learning_rate: 4.2679e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00039696692381050363.\n",
      "Epoch 27/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4488 - loss: 1.4612 - macro_f1_score: 0.4356\n",
      "Epoch 27: val_macro_f1_score did not improve from 0.15581\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 6s/step - accuracy: 0.4486 - loss: 1.4624 - macro_f1_score: 0.4355 - val_accuracy: 0.1339 - val_loss: 9.8252 - val_macro_f1_score: 0.0295 - learning_rate: 3.9697e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00036352492540989975.\n",
      "Epoch 28/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4818 - loss: 1.4867 - macro_f1_score: 0.4759\n",
      "Epoch 28: val_macro_f1_score improved from 0.15581 to 0.22438, saving model to C:\\Users\\FPT SHOP\\Speech_Emotion_Recognition\\working\\processed\\ravdess_ser_cnn_simple.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 4s/step - accuracy: 0.4812 - loss: 1.4871 - macro_f1_score: 0.4753 - val_accuracy: 0.2768 - val_loss: 2.8031 - val_macro_f1_score: 0.2244 - learning_rate: 3.6352e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0003272887977440182.\n",
      "Epoch 29/100\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4662 - loss: 1.4121 - macro_f1_score: 0.4409\n",
      "Epoch 29: val_macro_f1_score did not improve from 0.22438\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 4s/step - accuracy: 0.4659 - loss: 1.4139 - macro_f1_score: 0.4410 - val_accuracy: 0.2054 - val_loss: 3.8826 - val_macro_f1_score: 0.1350 - learning_rate: 3.2729e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0002891507945368058.\n",
      "Epoch 30/100\n",
      "\u001b[1m 1/28\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m2:05\u001b[0m 5s/step - accuracy: 0.4688 - loss: 1.2730 - macro_f1_score: 0.4497"
     ]
    }
   ],
   "source": [
    "# 71%\n",
    "# =========================\n",
    "# 7) Tham s·ªë tr√≠ch xu·∫•t & train\n",
    "# =========================\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, utils\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools, warnings, librosa, os, pandas as pd\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import Metric\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "EMOTION_MAP = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "SR_FEAT = 16000 \n",
    "\n",
    "NAME_TO_ID_MAP = {name: int(code)-1 for code, name in EMOTION_MAP.items()}\n",
    "ID_TO_NAME_MAP = {v: k for k, v in NAME_TO_ID_MAP.items()}\n",
    "\n",
    "# --- THAM S·ªê ---\n",
    "N_MELS = 128\n",
    "MAX_PAD_LEN = 200  # ~3.2 gi√¢y\n",
    "BATCH_SIZE = 32  # TƒÉng l·∫°i ƒë·ªÉ stable h∆°n\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = len(NAME_TO_ID_MAP)\n",
    "INPUT_SHAPE = (N_MELS, MAX_PAD_LEN, 1)  # CH·ªà D√ôNG LOG-MEL, B·ªé DELTA!\n",
    "\n",
    "MODEL_OUT = os.path.join(OUTPUT_DIR, \"ravdess_ser_cnn_simple.h5\")\n",
    "\n",
    "\n",
    "# THAY TH·∫æ TO√ÄN B·ªò CLASS MacroF1Score C≈® B·∫∞NG PHI√äN B·∫¢N N√ÄY\n",
    "\n",
    "class MacroF1Score(Metric):\n",
    "    def __init__(self, num_classes, name='macro_f1_score', **kwargs):\n",
    "        super(MacroF1Score, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        # S·ª≠ d·ª•ng tf.Variable ƒë·ªÉ c√°c bi·∫øn n√†y c√≥ th·ªÉ ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong ƒë·ªì th·ªã\n",
    "        self.true_positives = self.add_weight(name='tp', shape=(num_classes,), initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', shape=(num_classes,), initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', shape=(num_classes,), initializer='zeros')\n",
    "\n",
    "    @tf.function # Decorator n√†y s·∫Ω gi√∫p Keras chuy·ªÉn h√†m n√†y sang Graph mode m·ªôt c√°ch an to√†n\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_labels = K.argmax(y_true, axis=-1)  # (batch_size,)\n",
    "        y_pred_labels = K.argmax(y_pred, axis=-1)  # (batch_size,)\n",
    "\n",
    "        # Chuy·ªÉn ƒë·ªïi nh√£n v·ªÅ d·∫°ng one-hot ƒë·ªÉ d·ªÖ d√†ng t√≠nh to√°n TP, FP, FN cho t·ª´ng l·ªõp\n",
    "        y_true_one_hot = tf.one_hot(y_true_labels, self.num_classes) # (batch_size, num_classes)\n",
    "        y_pred_one_hot = tf.one_hot(y_pred_labels, self.num_classes) # (batch_size, num_classes)\n",
    "\n",
    "        # T√≠nh True Positives (TP) cho t·∫•t c·∫£ c√°c l·ªõp c√πng l√∫c\n",
    "        tp_batch = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=0) # (num_classes,)\n",
    "        self.true_positives.assign_add(tp_batch)\n",
    "\n",
    "        # T√≠nh False Positives (FP) cho t·∫•t c·∫£ c√°c l·ªõp c√πng l√∫c\n",
    "        fp_batch = tf.reduce_sum((1 - y_true_one_hot) * y_pred_one_hot, axis=0) # (num_classes,)\n",
    "        self.false_positives.assign_add(fp_batch)\n",
    "\n",
    "        # T√≠nh False Negatives (FN) cho t·∫•t c·∫£ c√°c l·ªõp c√πng l√∫c\n",
    "        fn_batch = tf.reduce_sum(y_true_one_hot * (1 - y_pred_one_hot), axis=0) # (num_classes,)\n",
    "        self.false_negatives.assign_add(fn_batch)\n",
    "\n",
    "    def result(self):\n",
    "        # ƒê·∫£m b·∫£o ph√©p chia kh√¥ng b·ªã l·ªói khi m·∫´u = 0\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + K.epsilon())\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + K.epsilon())\n",
    "        \n",
    "        # Calculate F1 for each class\n",
    "        f1_per_class = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "        \n",
    "        # Return macro average F1\n",
    "        return tf.reduce_mean(f1_per_class)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros(self.num_classes))\n",
    "        self.false_positives.assign(tf.zeros(self.num_classes))\n",
    "        self.false_negatives.assign(tf.zeros(self.num_classes))\n",
    "\n",
    "# Kh·ªüi t·∫°o metric F1-score v·ªõi s·ªë l·ªõp 8\n",
    "macro_f1 = MacroF1Score(num_classes=len(EMOTION_MAP))\n",
    "# =========================\n",
    "# 8) Tr√≠ch xu·∫•t features ƒê∆°N GI·∫¢N\n",
    "# =========================\n",
    "\n",
    "def add_white_noise(y, noise_factor=0.002):\n",
    "    \"\"\"Th√™m nhi·ªÖu nh·∫π.\"\"\"\n",
    "    noise = np.random.randn(len(y))\n",
    "    return y + noise_factor * noise\n",
    "\n",
    "def pitch_shift(y, sr=SR_FEAT, n_steps=2):\n",
    "    \"\"\"Thay ƒë·ªïi cao ƒë·ªô.\"\"\"\n",
    "    n = np.random.uniform(-n_steps, n_steps)\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=n)\n",
    "\n",
    "def pad_or_truncate(feat, max_len=MAX_PAD_LEN):\n",
    "    \"\"\"Pad ho·∫∑c c·∫Øt v·ªÅ max_len.\"\"\"\n",
    "    if feat.shape[1] < max_len:\n",
    "        pad_width = max_len - feat.shape[1]\n",
    "        feat = np.pad(feat, pad_width=((0, 0), (0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        feat = feat[:, :max_len, :]\n",
    "    return feat\n",
    "\n",
    "def extract_features(y, sr=SR_FEAT, n_mels=N_MELS, max_pad_len=MAX_PAD_LEN):\n",
    "    \"\"\"\n",
    "    CH·ªà D√ôNG LOG-MEL SPECTROGRAM - ƒê∆†N GI·∫¢N NH·∫§T!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # T√≠nh mel spectrogram\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            y=y, \n",
    "            sr=sr, \n",
    "            n_mels=n_mels,\n",
    "            n_fft=2048,\n",
    "            hop_length=512,\n",
    "            fmax=8000\n",
    "        )\n",
    "        \n",
    "        # Chuy·ªÉn sang dB scale\n",
    "        log_melspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "        \n",
    "        # Normalize v·ªÅ [-1, 1]\n",
    "        log_melspec = (log_melspec - log_melspec.mean()) / (log_melspec.std() + 1e-8)\n",
    "        \n",
    "        # Th√™m channel dimension\n",
    "        log_melspec = np.expand_dims(log_melspec, axis=-1)\n",
    "        \n",
    "        # Pad/truncate\n",
    "        log_melspec = pad_or_truncate(log_melspec, max_pad_len)\n",
    "        \n",
    "        return log_melspec\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# 9) Data Generator \n",
    "# =========================\n",
    "class AudioDataGenerator(utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_shape, num_classes, \n",
    "                 sr, n_mels, max_pad_len, shuffle=True, augment=False):\n",
    "        self.df = df\n",
    "        self.paths = df['file_path'].values\n",
    "        self.labels = df['label_id'].values \n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.max_pad_len = max_pad_len\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle:\n",
    "            self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_paths = [self.paths[k] for k in batch_indexes]\n",
    "        batch_labels = [self.labels[k] for k in batch_indexes]\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.input_shape))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, file_path in enumerate(batch_paths):\n",
    "            try:\n",
    "                # Load audio\n",
    "                y_audio, _ = librosa.load(file_path, sr=self.sr)\n",
    "                \n",
    "                # Augmentation √çT H∆†N\n",
    "                if self.augment and np.random.rand() < 0.5:\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        y_audio = add_white_noise(y_audio)\n",
    "                    else:\n",
    "                        y_audio = pitch_shift(y_audio, sr=self.sr)\n",
    "                \n",
    "                # Extract features\n",
    "                feat = extract_features(\n",
    "                    y_audio,\n",
    "                    sr=self.sr, \n",
    "                    n_mels=self.n_mels, \n",
    "                    max_pad_len=self.max_pad_len\n",
    "                )\n",
    "                \n",
    "                if feat is None:\n",
    "                    feat = np.zeros(self.input_shape) \n",
    "                    \n",
    "                X[i,] = feat\n",
    "                y[i] = batch_labels[i]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                X[i,] = np.zeros(self.input_shape)\n",
    "                y[i] = 0\n",
    "\n",
    "        return X, utils.to_categorical(y, num_classes=self.num_classes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# =========================\n",
    "# 10) Model ƒê∆†N GI·∫¢N NH∆ØNG HI·ªÜU QU·∫¢\n",
    "# =========================\n",
    "def build_cnn_model(input_shape, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Ki·∫øn tr√∫c t·∫≠p trung v√†o generalization.\n",
    "    \"\"\"\n",
    "    \n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Block 3\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Global pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layers - √çT H∆†N\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    \n",
    "    # Output\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inp, out)\n",
    "    \n",
    "    # Learning rate cao h∆°n v·ªõi decay\n",
    "    initial_lr = 0.0005 \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', macro_f1]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# 11) Plot functions\n",
    "# =========================\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix'):\n",
    "    if normalize:\n",
    "        cm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(classes))\n",
    "    plt.xticks(ticks, classes, rotation=45, ha='right')\n",
    "    plt.yticks(ticks, classes)\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        val = f\"{cm[i, j]:.2f}\" if normalize else f\"{int(cm[i, j])}\"\n",
    "        plt.text(j, i, val, ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=10)\n",
    "    plt.ylabel('True label', fontsize=12)\n",
    "    plt.xlabel('Predicted label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(14,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.title('Training and Validation Loss', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.title('Training and Validation Accuracy', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =========================\n",
    "# 12) Training v·ªõi COSINE ANNEALING\n",
    "# =========================\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "train_df_for_weights = pd.read_csv(os.path.join(OUTPUT_DIR, \"train_final.csv\"))\n",
    "y_train_for_weights = train_df_for_weights['label_id'].values\n",
    "class_labels_for_weights = np.unique(y_train_for_weights)\n",
    "class_weights_array = compute_class_weight('balanced', classes=class_labels_for_weights, y=y_train_for_weights)\n",
    "class_weights = dict(zip(class_labels_for_weights, class_weights_array))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Tr·ªçng s·ªë l·ªõp ƒë∆∞·ª£c t√≠nh to√°n ƒë·ªÉ x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng:\")\n",
    "for emotion_id, weight in class_weights.items():\n",
    "    print(f\"  - L·ªõp {emotion_id} ({ID_TO_NAME_MAP[emotion_id]}): {weight:.4f}\")\n",
    "print(\"=\"*60)\n",
    "def run_training():\n",
    "    \"\"\"Training v·ªõi cosine annealing schedule.\"\"\"\n",
    "    \n",
    "    def _filter_existing(df):\n",
    "        df = df.copy()\n",
    "        df[\"full_path\"] = df[\"file_path\"].apply(lambda p: str(ROOT_DIR / p) if isinstance(p, str) else None)\n",
    "        df[\"exists\"] = df[\"full_path\"].apply(lambda p: p is not None and os.path.exists(p))\n",
    "        \n",
    "        df = df[df[\"exists\"]].drop(columns=[\"exists\", \"full_path\"]) # Lo·∫°i b·ªè c·ªôt full_path sau khi l·ªçc\n",
    "        \n",
    "        # Sau khi l·ªçc, c·∫≠p nh·∫≠t file_path ƒë·ªÉ s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë√£ ki·ªÉm tra\n",
    "        df[\"file_path\"] = df[\"file_path\"].apply(lambda p: str(ROOT_DIR / p))\n",
    "        return df\n",
    "\n",
    "    # Load data\n",
    "    train_df = _filter_existing(pd.read_csv(os.path.join(OUTPUT_DIR, \"train_final.csv\")))\n",
    "    val_df   = _filter_existing(pd.read_csv(os.path.join(OUTPUT_DIR, \"val_final.csv\")))\n",
    "    test_df  = _filter_existing(pd.read_csv(os.path.join(OUTPUT_DIR, \"test_final.csv\")))\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìä Dataset:\")\n",
    "    print(f\"   Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "    print(f\"üìê Config:\")\n",
    "    print(f\"   Input: {INPUT_SHAPE}\")\n",
    "    print(f\"   Batch: {BATCH_SIZE}\")\n",
    "    print(\"=\"*60)\n",
    "    1\n",
    "    # Create generators\n",
    "    train_gen = AudioDataGenerator(\n",
    "        train_df, BATCH_SIZE, INPUT_SHAPE, NUM_CLASSES, \n",
    "        SR_FEAT, N_MELS, MAX_PAD_LEN, shuffle=True, augment=True\n",
    "    )\n",
    "    val_gen = AudioDataGenerator(\n",
    "        val_df, BATCH_SIZE, INPUT_SHAPE, NUM_CLASSES, \n",
    "        SR_FEAT, N_MELS, MAX_PAD_LEN, shuffle=False, augment=False\n",
    "    )\n",
    "    test_gen = AudioDataGenerator(\n",
    "        test_df, BATCH_SIZE, INPUT_SHAPE, NUM_CLASSES, \n",
    "        SR_FEAT, N_MELS, MAX_PAD_LEN, shuffle=False, augment=False\n",
    "    )\n",
    "    \n",
    "    # Build model\n",
    "    print(\"\\n  Building model...\")\n",
    "    model = build_cnn_model(input_shape=INPUT_SHAPE)\n",
    "    model.summary()\n",
    "    \n",
    "    # Cosine annealing schedule\n",
    "    def cosine_annealing(epoch, lr):\n",
    "        \"\"\"Cosine annealing schedule.\"\"\"\n",
    "        initial_lr = 0.0005\n",
    "        min_lr = 1e-7\n",
    "        T_max = 20  # Restart period\n",
    "        \n",
    "        cycle = np.floor(1 + epoch / (2 * T_max))\n",
    "        x = np.abs(epoch / T_max - 2 * cycle + 1)\n",
    "        new_lr = min_lr + (initial_lr - min_lr) * (1 + np.cos(np.pi * x)) / 2\n",
    "        return new_lr\n",
    "    \n",
    "    # Callbacks\n",
    "    cbs = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_macro_f1_score',\n",
    "            patience=30,  # TƒÉng patience\n",
    "            restore_best_weights=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.LearningRateScheduler(cosine_annealing, verbose=1),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            MODEL_OUT,\n",
    "            save_best_only=True,\n",
    "            monitor='val_macro_f1_score',\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    print(\"\\n Training...\")\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=cbs,\n",
    "        verbose=1,\n",
    "        class_weight=class_weights \n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" Testing...\")\n",
    "    model.load_weights(MODEL_OUT)\n",
    "    \n",
    "    loss, acc, f1_score_final = model.evaluate(test_gen, verbose=0, return_dict = True)\n",
    "    print(f\"\\n Test Results:\")\n",
    "    print(f\"   Loss:     {loss:.4f}\")\n",
    "    print(f\"   Accuracy: {acc*100:.2f}%\")\n",
    "    print(f\"   Macro F1:  {f1_score_final['macro_f1_score']:.4f}\") \n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Predictions\n",
    "    print(\"\\n Generating predictions...\")\n",
    "    y_true, y_pred = [], []\n",
    "    for i in range(len(test_gen)):\n",
    "        Xb, yb = test_gen[i]\n",
    "        pb = model.predict(Xb, verbose=0)\n",
    "        y_pred.extend(np.argmax(pb, axis=1)) \n",
    "        y_true.extend(np.argmax(yb, axis=1))\n",
    "\n",
    "    target_names = [ID_TO_NAME_MAP[i] for i in range(NUM_CLASSES)]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" Classification Report:\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # L·∫•y accuracy v√† f1_score t·ª´ classification_report ƒë·ªÉ hi·ªÉn th·ªã, v√¨ Keras evaluate ch·ªâ cho F1 t·ªïng\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, digits=4, output_dict=True)\n",
    "    \n",
    "    # In ra report d·∫°ng b·∫£ng ƒë·∫πp h∆°n\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
    "    \n",
    "    # L·∫•y macro avg f1 v√† accuracy t·ª´ report\n",
    "    final_macro_f1 = report['macro avg']['f1-score']\n",
    "    final_accuracy = report['accuracy']\n",
    "    \n",
    "    print(f\"\\nFinal Test Accuracy: {final_accuracy*100:.2f}%\")\n",
    "    print(f\"Final Test Macro F1: {final_macro_f1:.4f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    # Confusion matrices\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, classes=target_names, normalize=False, \n",
    "                         title=\"Confusion Matrix (Counts)\")\n",
    "    plot_confusion_matrix(cm, classes=target_names, normalize=True, \n",
    "                         title=\"Confusion Matrix (Normalized)\")\n",
    "    \n",
    "    plot_history(history)\n",
    "    \n",
    "    print(f\"\\n Done! Model saved: {MODEL_OUT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
