{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":256618,"sourceType":"datasetVersion","datasetId":107620}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # =========================\n# # 3. Duyệt file + lấy nhãn\n# # =========================\n# all_files = []\n# all_labels = []\n\n# # In ra các thư mục gốc mà os.walk sẽ đi qua\n# print(f\"Bắt đầu duyệt từ: {DATA_DIR}\")\n\n# for root, _, files in os.walk(DATA_DIR):\n#     print(f\"Đang duyệt trong thư mục: {root}\") # Thêm dòng này để kiểm tra\n#     for f in files:\n#         if f.endswith(\".wav\"):\n#             path = os.path.join(root, f)\n#             try:\n#                 code = f.split(\"-\")[2]\n#                 label = EMOTION_MAP[code]\n#             except IndexError: # Thay đổi except chung thành IndexError cụ thể hơn\n#                 print(f\"File không chuẩn hoặc tên không đúng định dạng: {f}\")\n#                 continue\n#             except KeyError: # Nếu code không có trong EMOTION_MAP\n#                 print(f\"Mã cảm xúc '{code}' không có trong EMOTION_MAP cho file: {f}\")\n#                 continue\n\n#             # Chỉ để kiểm tra 1 vài file đầu tiên để không quá dài\n#             if len(all_files) < 10: # Chỉ in 10 file đầu tiên\n#                 print(f\"  Thêm file: {path}\")\n#             all_files.append(path)\n#             all_labels.append(label)\n\n# print(f\"Tổng số file sau khi duyệt: {len(all_files)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# 1_preprocess_emotionid.py\n# =========================\nimport os\nimport librosa\nimport soundfile as sf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# =========================\n# 1. Cấu hình\n# =========================\nDATA_DIR = \"/kaggle/input/ravdess-emotional-speech-audio\"  # dataset gốc\nOUTPUT_DIR = \"/kaggle/working/processed\"  # thư mục lưu WAV + CSV\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Mapping code -> nhãn text\nEMOTION_MAP = {\n    '01': 'neutral',\n    '02': 'calm',\n    '03': 'happy',\n    '04': 'sad',\n    '05': 'angry',\n    '06': 'fearful',\n    '07': 'disgust',\n    '08': 'surprised'\n}\n\n# Mapping EmotionID -> label_id theo gốc (0-index)\nEMOTION_ID_TO_NUM = {k: int(k)-1 for k in EMOTION_MAP.keys()}\n# '01' -> 0, '02' -> 1, ..., '08' -> 7\n\n# =========================\n# 2. Hàm preprocess audio\n# =========================\ndef preprocess_audio(file_path, target_sr=16000):\n    try:\n        y, sr = librosa.load(file_path, sr=None)\n        if y.ndim > 1:\n            y = librosa.to_mono(y)\n        y_resampled = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n        return y_resampled, target_sr\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {file_path}: {e}\")\n        return None, None\n\n# =========================\n# 3. Duyệt file + lấy nhãn\n# =========================\nall_files = []\nall_labels = []\nall_label_ids = []\n\nfor root, _, files in os.walk(DATA_DIR):\n    for f in files:\n        if f.endswith(\".wav\"):\n            path = os.path.join(root, f)\n            try:\n                code = f.split(\"-\")[2]           # EmotionID từ filename\n                label_text = EMOTION_MAP[code]   # nhãn text\n                label_id = EMOTION_ID_TO_NUM[code]  # label_id theo gốc\n            except:\n                print(f\"File không chuẩn: {f}\")\n                continue\n            all_files.append(path)\n            all_labels.append(label_text)\n            all_label_ids.append(label_id)\n\nprint(f\"Tổng số file: {len(all_files)}\")\n\n# =========================\n# 4. Chia train/test\n# =========================\ntrain_files, test_files, train_labels, test_labels, train_label_ids, test_label_ids = train_test_split(\n    all_files, all_labels, all_label_ids,\n    test_size=0.2, stratify=all_label_ids, random_state=42\n)\n\n# =========================\n# 5. Hàm lưu WAV + trả paths\n# =========================\ndef save_wav(files, prefix):\n    paths = []\n    out_dir = os.path.join(OUTPUT_DIR, prefix)\n    os.makedirs(out_dir, exist_ok=True)\n    for i, path in enumerate(files):\n        y, sr = preprocess_audio(path)\n        if y is None:\n            continue\n        out_name = f\"{prefix}_{i}.wav\"\n        out_path = os.path.join(out_dir, out_name)\n        sf.write(out_path, y, sr)\n        paths.append(out_path)\n    return paths\n\ntrain_paths = save_wav(train_files, \"train\")\ntest_paths = save_wav(test_files, \"test\")\n\n# =========================\n# 6. Lưu CSV final\n# =========================\ntrain_df = pd.DataFrame({\n    \"file_path\": train_paths,\n    \"label\": train_labels,\n    \"label_id\": train_label_ids\n})\n\ntest_df = pd.DataFrame({\n    \"file_path\": test_paths,\n    \"label\": test_labels,\n    \"label_id\": test_label_ids\n})\n\n# Chia train -> validation\ntrain_df, val_df = train_test_split(\n    train_df, test_size=0.2, stratify=train_df[\"label_id\"], random_state=42\n)\n\n# Lưu CSV\ntrain_df.to_csv(os.path.join(OUTPUT_DIR, \"train_final.csv\"), index=False)\nval_df.to_csv(os.path.join(OUTPUT_DIR, \"val_final.csv\"), index=False)\ntest_df.to_csv(os.path.join(OUTPUT_DIR, \"test_final.csv\"), index=False)\n\nprint(f\"Số file train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\")\nprint(\"✅ Hoàn tất preprocess, CSV sẵn sàng train mô hình\")\nprint(\"Bảng label -> label_id:\", dict(zip(EMOTION_MAP.values(), EMOTION_ID_TO_NUM.values())))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:13:00.330858Z","iopub.execute_input":"2025-10-26T16:13:00.331513Z","iopub.status.idle":"2025-10-26T16:14:08.797986Z","shell.execute_reply.started":"2025-10-26T16:13:00.331490Z","shell.execute_reply":"2025-10-26T16:14:08.797306Z"}},"outputs":[{"name":"stdout","text":"Tổng số file: 2880\nSố file train: 1843, val: 461, test: 576\n✅ Hoàn tất preprocess, CSV sẵn sàng train mô hình\nBảng label -> label_id: {'neutral': 0, 'calm': 1, 'happy': 2, 'sad': 3, 'angry': 4, 'fearful': 5, 'disgust': 6, 'surprised': 7}\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Extracting features","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:14:08.799233Z","iopub.execute_input":"2025-10-26T16:14:08.799486Z","iopub.status.idle":"2025-10-26T16:14:08.803175Z","shell.execute_reply.started":"2025-10-26T16:14:08.799467Z","shell.execute_reply":"2025-10-26T16:14:08.802512Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ----------- 1. Config -----------\nSR = 16000             #16kHz\nN_FFT = 1024           # ~64 ms\nHOP = 256              # ~16 ms\nWIN = 1024\nN_MELS = 64\nN_MFCC = 13\n\nMAX_FRAMES = 500 \n\nUSE_LOGMEL = True\nUSE_MFCC39 = True\nUSE_CHROMA = True\nDATA_DIR = Path(\"/kaggle/working/processed\")\nFEAT_DIR = DATA_DIR / \"features\"\nFEAT_DIR.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:14:08.803860Z","iopub.execute_input":"2025-10-26T16:14:08.804126Z","iopub.status.idle":"2025-10-26T16:14:08.817364Z","shell.execute_reply.started":"2025-10-26T16:14:08.804108Z","shell.execute_reply":"2025-10-26T16:14:08.816582Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ----------- 2. Utils -----------\ndef load_wav(path, sr = SR):\n    # đọc wav, resample về SR,chuẩn hóa biên độ [-1, 1]\n    y, _ = librosa.load(Path(path), sr=sr, mono=True)\n    if np.max(np.abs(y)) > 0:\n        y = y / np.max(np.abs(y))\n    return y\n\ndef extract_logmel(y, sr = SR):\n    S = np.abs(librosa.stft(y, n_fft=N_FFT, hop_length=HOP, win_length=WIN))**2\n    M = librosa.feature.melspectrogram(S=S, sr=sr, n_mels=N_MELS)\n    logmel = librosa.power_to_db(M, ref=np.max)\n    return logmel\n\ndef extract_mfcc_block(y, sr = SR):\n    M = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT,\n                                       hop_length=HOP, win_length=WIN,\n                                       n_mels=N_MELS)\n    db = librosa.power_to_db(M, ref=np.max)\n    mfcc = librosa.feature.mfcc(S=db, n_mfcc=N_MFCC)\n    d1 = librosa.feature.delta(mfcc)\n    d2 = librosa.feature.delta(mfcc, order=2)\n    return np.concatenate([mfcc, d1, d2], axis=0)\n\ndef extract_chroma(y, sr=SR):\n    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP, win_length=WIN)\n    return chroma\n\ndef pad_or_trim_feat(X, T_target, pad_value=0.0):\n    # X: (C, T) -> (C, T_target) bằng cách cắt hoặc đệm 0 ở cuối\n    C, T = X.shape\n    if T == T_target:\n        return X\n    if T > T_target:\n        return X[:, :T_target]\n    pad = np.full((C, T_target - T), pad_value, dtype=X.dtype)\n    return np.concatenate([X, pad], axis=1)\n\ndef stack_features(y):\n    \"\"\"\n    Ghép các khối đặc trưng theo trục kênh (C):\n      - log-Mel: (N_MELS, T)\n      - MFCC39: (39, T)\n      - Chroma: (12, T)\n    Trả về: (C, T)\n    \"\"\"\n    feats = []\n    if USE_LOGMEL:\n        feats.append(extract_logmel(y))\n    if USE_MFCC39:\n        feats.append(extract_mfcc_block(y))\n    if USE_CHROMA:\n        feats.append(extract_chroma(y))\n    if len(feats) == 0:\n        raise ValueError(\"Bạn phải bật ít nhất một đặc trưng (LOGMEL/MFCC/CHROMA).\")\n    # Khớp T (trường hợp sai lệch 1-2 frame do làm tròn) bằng cách cắt theo T nhỏ nhất\n    T_min = min(f.shape[1] for f in feats)\n    feats = [f[:, :T_min] for f in feats]\n    return np.concatenate(feats, axis=0)\n\ndef compute_norm_stats(X):\n    \"\"\"X: (N, C, T) -> tính mean/std theo từng kênh C trên toàn bộ frames.\"\"\"\n    N, C, T = X.shape\n    flat = X.transpose(1, 0, 2).reshape(C, N*T)\n    mean = flat.mean(axis=1)\n    std = flat.std(axis=1) + 1e-8\n    return mean, std\n\ndef apply_norm(X, mean, std):\n    \"\"\"Pre-emphasis theo kênh: (N, C, T) -> normalized.\"\"\"\n    return (X - mean[None, :, None]) / std[None, :, None]\n\ndef read_split(split_name):\n    df = pd.read_csv(DATA_DIR / f\"{split_name}_final.csv\")\n    # Đảm bảo đúng kiểu\n    df[\"file_path\"] = df[\"file_path\"].astype(str)\n    df[\"label_id\"] = df[\"label_id\"].astype(int)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:14:08.819247Z","iopub.execute_input":"2025-10-26T16:14:08.819977Z","iopub.status.idle":"2025-10-26T16:14:08.836876Z","shell.execute_reply.started":"2025-10-26T16:14:08.819951Z","shell.execute_reply":"2025-10-26T16:14:08.836182Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 3) Trích xuất cho 1 split\n# =========================\ndef extract_split(split_name, T_target=None):\n    \"\"\"\n    split_name: 'train' | 'val' | 'test'\n    T_target: nếu None (thường cho train), sẽ chọn = min(T_max, MAX_FRAMES)\n    Trả về: X_pad (N,C,T), y (N,), paths (list), T_target (int)\n    \"\"\"\n    df = read_split(split_name)\n    X_list, y_list, paths = [], [], []\n\n    for path, label_id in zip(df[\"file_path\"].tolist(), df[\"label_id\"].tolist()):\n        y = load_wav(path)\n        F = stack_features(y)           # (C, T)\n        X_list.append(F)\n        y_list.append(int(label_id))\n        paths.append(str(path))\n\n    # Chọn số frame mục tiêu\n    if T_target is None:\n        T_max = max(x.shape[1] for x in X_list)\n        T_target = min(T_max, MAX_FRAMES)\n\n    # Pad/trim và xếp stack\n    X_pad = np.stack([pad_or_trim_feat(x, T_target) for x in X_list], axis=0)  # (N, C, T_target)\n    y = np.array(y_list, dtype=np.int64)\n\n    return X_pad, y, paths, T_target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:14:08.837520Z","iopub.execute_input":"2025-10-26T16:14:08.837730Z","iopub.status.idle":"2025-10-26T16:14:08.849980Z","shell.execute_reply.started":"2025-10-26T16:14:08.837714Z","shell.execute_reply":"2025-10-26T16:14:08.849252Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def main():\n    # ---- Train ----\n    X_train, y_train, train_paths, T_target = extract_split(\"train\", T_target=None)\n    mean, std = compute_norm_stats(X_train)\n    X_train = apply_norm(X_train, mean, std)\n\n    # ---- Val/Test: dùng cùng T_target & cùng mean/std của train ----\n    X_val, y_val, val_paths, _ = extract_split(\"val\", T_target=T_target)\n    X_test, y_test, test_paths, _ = extract_split(\"test\", T_target=T_target)\n\n    X_val  = apply_norm(X_val,  mean, std)\n    X_test = apply_norm(X_test, mean, std)\n\n    # ---- Lưu npy ----\n    np.save(FEAT_DIR / \"X_train.npy\", X_train)\n    np.save(FEAT_DIR / \"y_train.npy\", y_train)\n    np.save(FEAT_DIR / \"X_val.npy\",   X_val)\n    np.save(FEAT_DIR / \"y_val.npy\",   y_val)\n    np.save(FEAT_DIR / \"X_test.npy\",  X_test)\n    np.save(FEAT_DIR / \"y_test.npy\",  y_test)\n\n    # ---- Lưu meta ----\n    channels = X_train.shape[1]\n    meta = {\n        \"sr\": SR,\n        \"n_fft\": N_FFT,\n        \"hop\": HOP,\n        \"win\": WIN,\n        \"n_mels\": N_MELS,\n        \"n_mfcc\": N_MFCC,\n        \"use_logmel\": USE_LOGMEL,\n        \"use_mfcc39\": USE_MFCC39,\n        \"use_chroma\": USE_CHROMA,\n        \"channels\": int(channels),\n        \"frames_target\": int(X_train.shape[2]),\n        \"max_frames_cap\": MAX_FRAMES,\n        \"mean\": [float(m) for m in mean],\n        \"std\":  [float(s) for s in std],\n        \"train_size\": int(X_train.shape[0]),\n        \"val_size\": int(X_val.shape[0]),\n        \"test_size\": int(X_test.shape[0]),\n        \"train_paths_head\": train_paths[:3],  # để debug nhanh\n        \"val_paths_head\":   val_paths[:3],\n        \"test_paths_head\":  test_paths[:3],\n    }\n    with open(FEAT_DIR / \"meta.json\", \"w\") as f:\n        json.dump(meta, f, indent=2)\n\n    print(\"Done feature extraction.\")\n    print(f\"Shapes -> X_train {X_train.shape}, X_val {X_val.shape}, X_test {X_test.shape}\")\n    print(f\"Channels: {channels} (LOGMEL={USE_LOGMEL}, MFCC39={USE_MFCC39}, CHROMA={USE_CHROMA})\")\n    print(f\"Norm stats saved at: {FEAT_DIR/'meta.json'}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:14:08.850688Z","iopub.execute_input":"2025-10-26T16:14:08.850923Z","iopub.status.idle":"2025-10-26T16:15:13.962273Z","shell.execute_reply.started":"2025-10-26T16:14:08.850896Z","shell.execute_reply":"2025-10-26T16:15:13.961638Z"}},"outputs":[{"name":"stdout","text":"Done feature extraction.\nShapes -> X_train (1843, 115, 330), X_val (461, 115, 330), X_test (576, 115, 330)\nChannels: 115 (LOGMEL=True, MFCC39=True, CHROMA=True)\nNorm stats saved at: /kaggle/working/processed/features/meta.json\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# === 4. LOAD DATA ===\nimport numpy as np, os, json, torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\nFEATURES_DIR = \"/kaggle/working/processed/features\"  # hoặc đường dẫn bạn lưu\nOUT_DIR = \"/kaggle/working\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# Load đặc trưng và nhãn\nX_train = np.load(os.path.join(FEATURES_DIR, \"X_train.npy\"))\ny_train = np.load(os.path.join(FEATURES_DIR, \"y_train.npy\"))\nX_val   = np.load(os.path.join(FEATURES_DIR, \"X_val.npy\"))\ny_val   = np.load(os.path.join(FEATURES_DIR, \"y_val.npy\"))\nX_test  = np.load(os.path.join(FEATURES_DIR, \"X_test.npy\"))\ny_test  = np.load(os.path.join(FEATURES_DIR, \"y_test.npy\"))\n\nwith open(os.path.join(FEATURES_DIR, \"meta.json\")) as f:\n    meta = json.load(f)\n\nprint(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\nprint(\"Classes:\", len(set(y_train)))\n\n# Reshape cho CNN2D: (N, 1, C, T)\nX_train = X_train[:, None, :, :].astype(\"float32\")\nX_val   = X_val[:, None, :, :].astype(\"float32\")\nX_test  = X_test[:, None, :, :].astype(\"float32\")\n\n# Dataloader\nBATCH_SIZE = 32\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntrain_dl = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n                      batch_size=BATCH_SIZE, shuffle=True)\nval_dl = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)),\n                    batch_size=BATCH_SIZE)\ntest_dl = DataLoader(TensorDataset(torch.tensor(X_test), torch.tensor(y_test)),\n                     batch_size=BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:17:33.472400Z","iopub.execute_input":"2025-10-26T16:17:33.472671Z","iopub.status.idle":"2025-10-26T16:17:37.847931Z","shell.execute_reply.started":"2025-10-26T16:17:33.472651Z","shell.execute_reply":"2025-10-26T16:17:37.847302Z"}},"outputs":[{"name":"stdout","text":"Shapes: (1843, 115, 330) (461, 115, 330) (576, 115, 330)\nClasses: 8\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# === 5. MODEL DEFINITION ===\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SER_CNN(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 32, (5,7), padding=(2,3)), nn.BatchNorm2d(32), nn.ReLU(),\n            nn.MaxPool2d((2,2)),\n            nn.Conv2d(32, 64, (3,5), padding=(1,2)), nn.BatchNorm2d(64), nn.ReLU(),\n            nn.MaxPool2d((2,2)),\n            nn.Conv2d(64, 128, (3,5), padding=(1,2)), nn.BatchNorm2d(128), nn.ReLU(),\n            nn.Dropout(0.25),\n        )\n        self.pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(128, 128), nn.ReLU(), nn.Dropout(0.3),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pool(x)\n        return self.fc(x)\n\n# Khởi tạo\nnum_classes = len(set(y_train))\nmodel = SER_CNN(num_classes).to(device)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:17:37.849085Z","iopub.execute_input":"2025-10-26T16:17:37.849538Z","iopub.status.idle":"2025-10-26T16:17:38.059632Z","shell.execute_reply.started":"2025-10-26T16:17:37.849510Z","shell.execute_reply":"2025-10-26T16:17:38.059017Z"}},"outputs":[{"name":"stdout","text":"SER_CNN(\n  (conv): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(5, 7), stride=(1, 1), padding=(2, 3))\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(32, 64, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU()\n    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(64, 128, kernel_size=(3, 5), stride=(1, 1), padding=(1, 2))\n    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout(p=0.25, inplace=False)\n  )\n  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=128, out_features=128, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=0.3, inplace=False)\n    (4): Linear(in_features=128, out_features=8, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# === 6. TRAINING SETUP ===\nfrom sklearn.metrics import f1_score\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n\ndef evaluate(model, dataloader):\n    model.eval()\n    all_true, all_pred = [], []\n    with torch.no_grad():\n        for xb, yb in dataloader:\n            xb, yb = xb.to(device), yb.to(device)\n            pred = model(xb).argmax(1)\n            all_true.append(yb.cpu().numpy())\n            all_pred.append(pred.cpu().numpy())\n    y_true = np.concatenate(all_true); y_pred = np.concatenate(all_pred)\n    f1 = f1_score(y_true, y_pred, average=\"macro\")\n    acc = (y_true == y_pred).mean()\n    return acc, f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:17:41.021121Z","iopub.execute_input":"2025-10-26T16:17:41.021701Z","iopub.status.idle":"2025-10-26T16:17:43.664338Z","shell.execute_reply.started":"2025-10-26T16:17:41.021679Z","shell.execute_reply":"2025-10-26T16:17:43.663565Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# === 7. TRAIN LOOP ===\nEPOCHS = 30\nbest_f1, patience, left = -1, 5, 5\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    total_loss = 0\n    for xb, yb in train_dl:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(xb), yb)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * xb.size(0)\n    train_loss = total_loss / len(train_dl.dataset)\n    \n    val_acc, val_f1 = evaluate(model, val_dl)\n    scheduler.step(val_f1)\n\n    print(f\"Epoch {epoch:02d}: loss={train_loss:.4f}  val_acc={val_acc:.3f}  val_f1={val_f1:.3f}\")\n\n    if val_f1 > best_f1:\n        best_f1, left = val_f1, patience\n        torch.save(model.state_dict(), os.path.join(OUT_DIR, \"ser_best.pt\"))\n    else:\n        left -= 1\n        if left == 0:\n            print(\"⏹ Early stopping.\")\n            break\n\nprint(\"Best val F1:\", best_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:17:47.670674Z","iopub.execute_input":"2025-10-26T16:17:47.671097Z","iopub.status.idle":"2025-10-26T16:21:20.368077Z","shell.execute_reply.started":"2025-10-26T16:17:47.671075Z","shell.execute_reply":"2025-10-26T16:21:20.367371Z"}},"outputs":[{"name":"stdout","text":"Epoch 01: loss=2.0270  val_acc=0.208  val_f1=0.106\nEpoch 02: loss=1.9353  val_acc=0.269  val_f1=0.185\nEpoch 03: loss=1.8284  val_acc=0.345  val_f1=0.244\nEpoch 04: loss=1.7345  val_acc=0.371  val_f1=0.281\nEpoch 05: loss=1.6596  val_acc=0.397  val_f1=0.310\nEpoch 06: loss=1.6005  val_acc=0.230  val_f1=0.142\nEpoch 07: loss=1.5712  val_acc=0.432  val_f1=0.342\nEpoch 08: loss=1.5135  val_acc=0.299  val_f1=0.237\nEpoch 09: loss=1.4921  val_acc=0.141  val_f1=0.043\nEpoch 10: loss=1.4379  val_acc=0.330  val_f1=0.268\nEpoch 11: loss=1.3965  val_acc=0.408  val_f1=0.347\nEpoch 12: loss=1.3670  val_acc=0.221  val_f1=0.156\nEpoch 13: loss=1.3204  val_acc=0.213  val_f1=0.128\nEpoch 14: loss=1.3174  val_acc=0.219  val_f1=0.120\nEpoch 15: loss=1.2788  val_acc=0.425  val_f1=0.351\nEpoch 16: loss=1.2275  val_acc=0.210  val_f1=0.133\nEpoch 17: loss=1.1801  val_acc=0.176  val_f1=0.094\nEpoch 18: loss=1.1399  val_acc=0.443  val_f1=0.403\nEpoch 19: loss=1.1282  val_acc=0.267  val_f1=0.129\nEpoch 20: loss=1.1045  val_acc=0.134  val_f1=0.030\nEpoch 21: loss=1.0835  val_acc=0.254  val_f1=0.124\nEpoch 22: loss=1.0311  val_acc=0.260  val_f1=0.135\nEpoch 23: loss=0.9768  val_acc=0.579  val_f1=0.529\nEpoch 24: loss=0.9335  val_acc=0.171  val_f1=0.097\nEpoch 25: loss=0.8930  val_acc=0.547  val_f1=0.527\nEpoch 26: loss=0.8836  val_acc=0.319  val_f1=0.228\nEpoch 27: loss=0.8753  val_acc=0.297  val_f1=0.237\nEpoch 28: loss=0.8204  val_acc=0.475  val_f1=0.448\n⏹ Early stopping.\nBest val F1: 0.5289169175863404\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# === 8. TEST EVALUATION ===\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nmodel.load_state_dict(torch.load(os.path.join(OUT_DIR, \"ser_best.pt\"), map_location=device))\nacc, f1 = evaluate(model, test_dl)\nprint(f\"\\n Test Accuracy: {acc:.4f} | Macro-F1: {f1:.4f}\")\n\n# In báo cáo chi tiết\ny_true, y_pred = [], []\nmodel.eval()\nwith torch.no_grad():\n    for xb, yb in test_dl:\n        xb = xb.to(device)\n        preds = model(xb).argmax(1).cpu().numpy()\n        y_true.append(yb.numpy()); y_pred.append(preds)\ny_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n\nprint(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T16:21:32.922571Z","iopub.execute_input":"2025-10-26T16:21:32.923098Z","iopub.status.idle":"2025-10-26T16:21:33.637017Z","shell.execute_reply.started":"2025-10-26T16:21:32.923071Z","shell.execute_reply":"2025-10-26T16:21:33.636371Z"}},"outputs":[{"name":"stdout","text":"\n Test Accuracy: 0.5729 | Macro-F1: 0.5341\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.4000    0.1053    0.1667        38\n           1     0.5000    1.0000    0.6667        76\n           2     0.7667    0.2987    0.4299        77\n           3     0.2895    0.4286    0.3455        77\n           4     0.8824    0.7792    0.8276        77\n           5     0.4839    0.3896    0.4317        77\n           6     0.7531    0.7922    0.7722        77\n           7     0.7288    0.5584    0.6324        77\n\n    accuracy                         0.5729       576\n   macro avg     0.6005    0.5440    0.5341       576\nweighted avg     0.6143    0.5729    0.5587       576\n\n\nConfusion Matrix:\n [[ 4 26  0  8  0  0  0  0]\n [ 0 76  0  0  0  0  0  0]\n [ 3  5 23 22  1 12  5  6]\n [ 2 32  0 33  0  4  6  0]\n [ 0  0  0  1 60  3  7  6]\n [ 0  5  1 37  0 30  0  4]\n [ 0  6  0  7  3  0 61  0]\n [ 1  2  6  6  4 13  2 43]]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}