{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPbB8Q+DvC4E8umDBzt0Tn7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import librosa\n","import soundfile as sf\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","from google.colab import drive\n","\n","# ==========================================\n","# 1. MOUNT DRIVE VÃ€ Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN\n","# ==========================================\n","print(\"ğŸ”— Äang káº¿t ná»‘i vá»›i Google Drive...\")\n","drive.mount('/content/drive')\n","\n","BASE_DIR = \"/content/drive/MyDrive/Speech_Emotion_Recognition\"\n","INPUT_DIR = os.path.join(BASE_DIR, \"input\")\n","RAVDESS_DIR = os.path.join(INPUT_DIR, \"ravdess-emotional-speech-audio\")\n","TESS_DIR = os.path.join(INPUT_DIR, \"TESS Toronto emotional speech set data\")\n","\n","OUTPUT_DIR = os.path.join(BASE_DIR, \"working/processed\")\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# ==========================================\n","# 2. Cáº¤U HÃŒNH MAPPING (Gá»˜P NEUTRAL & CALM)\n","# ==========================================\n","RAVDESS_MAP = {\n","    '01': 'neutral', '02': 'neutral', # Gá»™p Calm vÃ o Neutral\n","    '03': 'happy',   '04': 'sad',\n","    '05': 'angry',   '06': 'fearful',\n","    '07': 'disgust', '08': 'surprised'\n","}\n","\n","TESS_MAP = {\n","    'neutral': 'neutral',\n","    'happy': 'happy',\n","    'sad': 'sad',\n","    'angry': 'angry',\n","    'fear': 'fearful',\n","    'disgust': 'disgust',\n","    'ps': 'surprised'\n","}\n","\n","EMOTION_TO_ID = {\n","    'neutral': 0, 'happy': 1, 'sad': 2, 'angry': 3,\n","    'fearful': 4, 'disgust': 5, 'surprised': 6\n","}\n","\n","# =========================\n","# 3. HÃ€M Há»– TRá»¢\n","# =========================\n","def preprocess_audio(file_path, target_sr=16000):\n","    try:\n","        y, sr = librosa.load(file_path, sr=None)\n","        if y.ndim > 1: y = librosa.to_mono(y)\n","        y_resampled = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n","        return y_resampled, target_sr\n","    except Exception as e:\n","        return None, None\n","\n","# ==========================================\n","# 4. DUYá»†T FILE VÃ€ Táº O DANH SÃCH Gá»C\n","# ==========================================\n","all_data = []\n","\n","print(\"ğŸ“‚ Äang quÃ©t tá»‡p tin dá»¯ liá»‡u...\")\n","\n","# QuÃ©t RAVDESS\n","for root, _, files in os.walk(RAVDESS_DIR):\n","    for f in files:\n","        if f.endswith(\".wav\"):\n","            parts = f.split('-')\n","            if len(parts) >= 3:\n","                emotion_name = RAVDESS_MAP.get(parts[2])\n","                if emotion_name:\n","                    all_data.append({\n","                        'raw_path': os.path.join(root, f),\n","                        'label_id': EMOTION_TO_ID[emotion_name]\n","                    })\n","\n","# QuÃ©t TESS\n","for root, _, files in os.walk(TESS_DIR):\n","    for f in files:\n","        if f.endswith(\".wav\"):\n","            emo = f.lower().split('.')[0].split('_')[-1]\n","            emotion_name = TESS_MAP.get(emo)\n","            if emotion_name:\n","                all_data.append({\n","                    'raw_path': os.path.join(root, f),\n","                    'label_id': EMOTION_TO_ID[emotion_name]\n","                })\n","\n","df_raw = pd.DataFrame(all_data)\n","print(f\"âœ… TÃ¬m tháº¥y tá»•ng cá»™ng: {len(df_raw)} máº«u.\")\n","print(\"ğŸ“Š PhÃ¢n bá»• dá»¯ liá»‡u trÆ°á»›c khi cÃ¢n báº±ng:\\n\", df_raw['label_id'].value_counts())\n","\n","# ==========================================\n","# 5. CHIA Táº¬P Dá»® LIá»†U\n","# ==========================================\n","# Chia Train_Full (80%) vÃ  Test (20%)\n","df_train_full, df_test = train_test_split(\n","    df_raw, test_size=0.2, stratify=df_raw['label_id'], random_state=42\n",")\n","\n","# Chia tiáº¿p Validation (15% cá»§a Train_Full)\n","df_train, df_val = train_test_split(\n","    df_train_full, test_size=0.15, stratify=df_train_full['label_id'], random_state=42\n",")\n","\n","# ==========================================\n","# 6. Xá»¬ LÃ IMBALANCE (OVERSAMPLING TRÃŠN TRAIN)\n","# ==========================================\n","print(\"\\nâš–ï¸ Äang xá»­ lÃ½ cÃ¢n báº±ng dá»¯ liá»‡u trÃªn táº­p Train...\")\n","max_size = df_train['label_id'].value_counts().max()\n","lst_balanced = []\n","\n","for class_id in df_train['label_id'].unique():\n","    df_class = df_train[df_train['label_id'] == class_id]\n","    df_class_oversampled = resample(df_class,\n","                                    replace=True,      # NhÃ¢n báº£n máº«u\n","                                    n_samples=max_size, # ÄÆ°a vá» báº±ng sá»‘ lÆ°á»£ng máº«u lá»›n nháº¥t\n","                                    random_state=42)\n","    lst_balanced.append(df_class_oversampled)\n","\n","df_train_balanced = pd.concat(lst_balanced)\n","print(\"ğŸ“Š PhÃ¢n bá»• dá»¯ liá»‡u sau khi cÃ¢n báº±ng táº­p Train:\\n\", df_train_balanced['label_id'].value_counts())\n","\n","# ==========================================\n","# 7. TIá»€N Xá»¬ LÃ Ã‚M THANH VÃ€ LÆ¯U FILE\n","# ==========================================\n","def process_and_save_dataset(df, folder_name):\n","    print(f\"ğŸš€ Äang xá»­ lÃ½ audio cho táº­p {folder_name}...\")\n","    # Chá»‰ láº¥y cÃ¡c Ä‘Æ°á»ng dáº«n duy nháº¥t Ä‘á»ƒ xá»­ lÃ½ (trÃ¡nh xá»­ lÃ½ láº·p láº¡i file oversampled)\n","    unique_files = df['raw_path'].unique()\n","    path_map = {} # Map tá»« raw_path sang processed_path\n","\n","    save_path = os.path.join(OUTPUT_DIR, folder_name)\n","    os.makedirs(save_path, exist_ok=True)\n","\n","    for i, raw_f in enumerate(unique_files):\n","        y, sr = preprocess_audio(raw_f)\n","        if y is not None:\n","            new_name = f\"{folder_name}_{i}.wav\"\n","            full_save_path = os.path.join(save_path, new_name)\n","            sf.write(full_save_path, y, sr)\n","            path_map[raw_f] = os.path.join(folder_name, new_name)\n","\n","        if (i+1) % 400 == 0: print(f\"   --> ÄÃ£ lÆ°u {i+1} file...\")\n","\n","    # Cáº­p nháº­t Ä‘Æ°á»ng dáº«n má»›i vÃ o dataframe\n","    df['file_path'] = df['raw_path'].map(path_map)\n","    return df.dropna(subset=['file_path'])\n","\n","# Xá»­ lÃ½ vÃ  lÆ°u\n","df_train_final = process_and_save_dataset(df_train_balanced, \"train\")\n","df_val_final = process_and_save_dataset(df_val, \"val\")\n","df_test_final = process_and_save_dataset(df_test, \"test\")\n","\n","# ==========================================\n","# 8. LÆ¯U CSV CUá»I CÃ™NG\n","# ==========================================\n","cols = ['file_path', 'label_id']\n","df_train_final[cols].to_csv(os.path.join(OUTPUT_DIR, \"train_final.csv\"), index=False)\n","df_val_final[cols].to_csv(os.path.join(OUTPUT_DIR, \"val_final.csv\"), index=False)\n","df_test_final[cols].to_csv(os.path.join(OUTPUT_DIR, \"test_final.csv\"), index=False)\n","\n","print(\"\\n\" + \"=\"*40)\n","print(\"ğŸ¯ HOÃ€N Táº¤T!\")\n","print(f\"ğŸ“Š Káº¿t quáº£ cuá»‘i cÃ¹ng (Sá»‘ dÃ²ng trong CSV):\")\n","print(f\"   - Train (Balanced): {len(df_train_final)}\")\n","print(f\"   - Val: {len(df_val_final)}\")\n","print(f\"   - Test: {len(df_test_final)}\")\n","print(\"=\"*40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qpi6TuquVTTV","executionInfo":{"status":"ok","timestamp":1766749239861,"user_tz":-420,"elapsed":1775506,"user":{"displayName":"Duc Manh Deanjames","userId":"07257301992281346172"}},"outputId":"0f805821-7f45-410b-b8fc-96960b8a2ade"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”— Äang káº¿t ná»‘i vá»›i Google Drive...\n","Mounted at /content/drive\n","ğŸ“‚ Äang quÃ©t tá»‡p tin dá»¯ liá»‡u...\n","âœ… TÃ¬m tháº¥y tá»•ng cá»™ng: 4240 máº«u.\n","ğŸ“Š PhÃ¢n bá»• dá»¯ liá»‡u trÆ°á»›c khi cÃ¢n báº±ng:\n"," label_id\n","0    688\n","1    592\n","3    592\n","2    592\n","4    592\n","6    592\n","5    592\n","Name: count, dtype: int64\n","\n","âš–ï¸ Äang xá»­ lÃ½ cÃ¢n báº±ng dá»¯ liá»‡u trÃªn táº­p Train...\n","ğŸ“Š PhÃ¢n bá»• dá»¯ liá»‡u sau khi cÃ¢n báº±ng táº­p Train:\n"," label_id\n","3    467\n","5    467\n","2    467\n","1    467\n","0    467\n","6    467\n","4    467\n","Name: count, dtype: int64\n","ğŸš€ Äang xá»­ lÃ½ audio cho táº­p train...\n","   --> ÄÃ£ lÆ°u 400 file...\n","   --> ÄÃ£ lÆ°u 800 file...\n","   --> ÄÃ£ lÆ°u 1200 file...\n","   --> ÄÃ£ lÆ°u 1600 file...\n","ğŸš€ Äang xá»­ lÃ½ audio cho táº­p val...\n","   --> ÄÃ£ lÆ°u 400 file...\n","ğŸš€ Äang xá»­ lÃ½ audio cho táº­p test...\n","   --> ÄÃ£ lÆ°u 400 file...\n","   --> ÄÃ£ lÆ°u 800 file...\n","\n","========================================\n","ğŸ¯ HOÃ€N Táº¤T!\n","ğŸ“Š Káº¿t quáº£ cuá»‘i cÃ¹ng (Sá»‘ dÃ²ng trong CSV):\n","   - Train (Balanced): 3269\n","   - Val: 509\n","   - Test: 848\n","========================================\n"]}]}]}